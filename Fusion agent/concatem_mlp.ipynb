{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_r2KB0k8q_I",
        "outputId": "8c207d76-69ea-44b9-d008-c3a8ef947d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haMz9drd8rbr",
        "outputId": "cc223839-b46e-424d-f44d-e4365a642195"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "-88jXdiaUboi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFHJYCoX9Gwz",
        "outputId": "f151db43-259f-461a-a4c5-d79380c0a9f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'28tech Lập Trình Python 2024 Từ Cơ Bản Tới Nâng Cao Qua 120 Video Và 300 Bài Tập Thực Hành'\n",
            "'Advanced RAG + ReRank on using LangChain.ipynb'\n",
            " AgriCarbonDEX.docx\n",
            "'Blockchain (1).drawio.png'\n",
            " Blockchain.drawio\n",
            " Blockchain.drawio.png\n",
            " cfg_node_embeddings.npy\n",
            "'Copy of RAG-SmartVuln.drawio'\n",
            " DACN-MultiAgent-MultiModal-RAG\n",
            " data-MLP.ipynb\n",
            " detected.evm\n",
            " detected.sol\n",
            "'ERC721-ERC20 (1).gdoc'\n",
            " ERC721-ERC20.gdoc\n",
            " EtherSolve.jar\n",
            "'fusion agent.ipynb'\n",
            " GATv2-CFG.ipynb\n",
            " gatv2_embeddings\n",
            " graph.dot\n",
            " graph.png\n",
            " hello.evm\n",
            " hello.sol\n",
            " IDPS.drawio\n",
            " index.html\n",
            " Lab_4.ipynb\n",
            " Lab_5-Nhom11.ipynb\n",
            " MLP-dts.ipynb\n",
            " multiagent_RAG+web_assistant.ipynb\n",
            " Multi_agent_with_explanation.ipynb\n",
            "'[NT522.P21.ANTT.2]Lab2_Nhom11.ipynb'\n",
            "'Ollama-opensource Phi-3-14b.ipynb'\n",
            " output\n",
            " PII\n",
            "'PII data.ipynb'\n",
            "'PII-masking (1).drawio.png'\n",
            " PII-masking.drawio\n",
            " PII-masking.drawio.png\n",
            " pii_sent_response_done.ipynb\n",
            " Proxy.evm\n",
            " rag_evaluation.ipynb\n",
            " RAG-SmartVuln.drawio\n",
            " report.json\n",
            "'scalm-graph (1).ipynb'\n",
            " scalm-graph-clean.ipynb\n",
            " solidity_code_with_labels.xlsx\n",
            " temp.evm\n",
            " temp.sol\n",
            " test.xlsx\n",
            " unsloth_compiled_cache\n",
            " Untitled0.ipynb\n",
            " utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas scikit-learn torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqVSGE6h9V9i",
        "outputId": "50dde0ca-4a3c-4d3a-87a4-670df5ba9eda"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#test on detected input by user\n"
      ],
      "metadata": {
        "id": "a8xfAg5RMRay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## cfg"
      ],
      "metadata": {
        "id": "OGx6CSHmMnKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#process to get evm file\n",
        "import re\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "# 1. Cài solc-select (chạy một lần)\n",
        "!pip install solc-select\n",
        "!solc-select install 0.8.0  # Cài sẵn một version để thử\n",
        "\n",
        "#user input is a detected code\n",
        "contract_code = \"\"\"\n",
        "// SPDX-License-Identifier: MIT\n",
        "pragma solidity ^0.4.17;\n",
        "\n",
        "contract Solidity_OverflowUnderflow {\n",
        "    uint8 public balance;\n",
        "\n",
        "    constructor() public {\n",
        "        balance = 255; // Maximum value of uint8\n",
        "    }\n",
        "\n",
        "    // Increments the balance by a given value\n",
        "    function increment(uint8 value) public {\n",
        "        balance += value; // Vulnerable to overflow\n",
        "    }\n",
        "\n",
        "    // Decrements the balance by a given value\n",
        "    function decrement(uint8 value) public {\n",
        "        balance -= value; // Vulnerable to underflow\n",
        "    }\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 2. Tự động trích xuất phiên bản từ mã Solidity\n",
        "\n",
        "def extract_version(pragma_str):\n",
        "    match = re.search(r\"pragma\\s+solidity\\s+\\^?([0-9]+\\.[0-9]+(?:\\.[0-9]+)?)\", pragma_str)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        raise ValueError(\"Solidity version not found in pragma.\")\n",
        "\n",
        "version = extract_version(contract_code)\n",
        "print(f\"Detected Solidity version: {version}\")\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_contract_name(code: str) -> str:\n",
        "    match = re.search(r'\\bcontract\\s+([A-Za-z_][A-Za-z0-9_]*)\\b', code)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        raise ValueError(\"No contract name found in code.\")\n",
        "\n",
        "\n",
        "# 3. Cài và chọn đúng phiên bản với solc-select\n",
        "# Cài solc version nếu chưa có\n",
        "!solc-select install {version}\n",
        "\n",
        "# Chọn đúng version để dùng\n",
        "!solc-select use {version}\n",
        "\n",
        "# 4. Ghi mã vào file và compile\n",
        "with open(\"detected.sol\", \"w\") as f:\n",
        "    f.write(contract_code)\n",
        "\n",
        "#5. Trích tên contract\n",
        "contract_name = extract_contract_name(contract_code)\n",
        "print(f\"Detected contract name: {contract_name}\")\n",
        "\n",
        "#get evm\n",
        "!solc --bin-runtime detected.sol -o output --overwrite\n",
        "!cp output/{contract_name}.bin-runtime detected.evm\n",
        "\n",
        "!java -jar EtherSolve.jar -c -H detected.evm\n",
        "!java -jar EtherSolve.jar -r -d -o graph.dot detected.evm\n",
        "!java -jar EtherSolve.jar -r -j -o report.json detected.evm\n",
        "# !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cpu.html\n",
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLSCAQijJqAX",
        "outputId": "00f39a41-262a-4a32-9518-27928aa38e10"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: solc-select in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pycryptodome>=3.4.6 in /usr/local/lib/python3.11/dist-packages (from solc-select) (3.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from solc-select) (24.2)\n",
            "Installing solc '0.8.0'...\n",
            "Version '0.8.0' installed.\n",
            "Detected Solidity version: 0.4.17\n",
            "Installing solc '0.4.17'...\n",
            "Version '0.4.17' installed.\n",
            "Switched global version to 0.4.17\n",
            "Detected contract name: Solidity_OverflowUnderflow\n",
            "detected.sol:8:16: Error: Expected identifier, got 'LParen'\n",
            "    constructor() public {\n",
            "               ^\n",
            "cp: cannot stat 'output/Solidity_OverflowUnderflow.bin-runtime': No such file or directory\n",
            "\u001b[31m\u001b[1mjava.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1\u001b[21m\u001b[39m\u001b[0m\n",
            "\u001b[3m\tat parseTree.Contract.<init>(Contract.java:48)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat parseTree.Contract.<init>(Contract.java:62)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat cli.MainCLI.call(MainCLI.java:73)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat cli.MainCLI.call(MainCLI.java:24)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine.executeUserObject(CommandLine.java:1933)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine.access$1100(CommandLine.java:145)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine$RunLast.executeUserObjectOfLastSubcommandWithSameParent(CommandLine.java:2332)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine$RunLast.handle(CommandLine.java:2326)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine$RunLast.handle(CommandLine.java:2291)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine$AbstractParseResultHandler.execute(CommandLine.java:2159)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat picocli.CommandLine.execute(CommandLine.java:2058)\u001b[23m\u001b[0m\n",
            "\u001b[3m\tat cli.MainCLI.main(MainCLI.java:118)\u001b[23m\u001b[0m\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from torch.nn import Embedding\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATv2Conv\n",
        "\n",
        "# === Step 1: Load CFG JSON ===\n",
        "with open(\"report.json\") as f:\n",
        "    cfg_json = json.load(f)\n",
        "\n",
        "nodes = cfg_json[\"runtimeCfg\"][\"nodes\"]\n",
        "edges_raw = cfg_json[\"runtimeCfg\"][\"successors\"]\n",
        "\n",
        "# === Step 2: Build opcode vocabulary and encode opcodes ===\n",
        "opcode_vocab = {}\n",
        "def opcode_to_index(op):\n",
        "    if op not in opcode_vocab:\n",
        "        opcode_vocab[op] = len(opcode_vocab)\n",
        "    return opcode_vocab[op]\n",
        "\n",
        "max_op_len = 20\n",
        "node_features = []\n",
        "\n",
        "for node in nodes:\n",
        "    if node[\"parsedOpcodes\"]:\n",
        "        opcodes = [line.split(\":\")[1].strip().split()[0]\n",
        "                   for line in node[\"parsedOpcodes\"].split(\"\\n\")]\n",
        "        opcode_ids = [opcode_to_index(op) for op in opcodes]\n",
        "        padded = opcode_ids[:max_op_len] + [0] * (max_op_len - len(opcode_ids))\n",
        "    else:\n",
        "        padded = [0] * max_op_len\n",
        "    node_features.append(padded)\n",
        "\n",
        "x = torch.tensor(node_features, dtype=torch.long)  # [num_nodes, max_op_len]\n",
        "\n",
        "# === Step 3: Embed opcodes using Embedding layer ===\n",
        "embed_dim = 16\n",
        "embed = Embedding(len(opcode_vocab), embed_dim)\n",
        "x_embed = embed(x).mean(dim=1)  # [num_nodes, embed_dim]\n",
        "\n",
        "# === Step 4: Convert offset-based edges to index-based ===\n",
        "offset_to_idx = {node[\"offset\"]: idx for idx, node in enumerate(nodes)}\n",
        "\n",
        "edge_index = []\n",
        "for entry in edges_raw:\n",
        "    src_offset = entry[\"from\"]\n",
        "    for dst_offset in entry[\"to\"]:\n",
        "        if src_offset in offset_to_idx and dst_offset in offset_to_idx:\n",
        "            src_idx = offset_to_idx[src_offset]\n",
        "            dst_idx = offset_to_idx[dst_offset]\n",
        "            edge_index.append([src_idx, dst_idx])\n",
        "\n",
        "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "\n",
        "# === Step 5: Create PyTorch Geometric Data object ===\n",
        "data = Data(x=x_embed, edge_index=edge_index)\n",
        "print(data)\n",
        "\n",
        "# === Step 6: Apply GATv2 ===\n",
        "gat = GATv2Conv(in_channels=embed_dim, out_channels=32, heads=2)\n",
        "cfg_vec = gat(data.x, data.edge_index)\n",
        "# print(\"GATv2 output shape:\", output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQPPWhk_MjHH",
        "outputId": "b31d2b8b-cf07-4c06-c8d7-290e96ba63ee"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[53, 16], edge_index=[2, 80])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_vec.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQfr8Kh1QHex",
        "outputId": "8a0834ea-033f-4f31-d314-1762de6acdb0"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([53, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## codebert"
      ],
      "metadata": {
        "id": "4hFtCfprM0Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)        # → 2.6.0+cu118\n",
        "print(torch.version.cuda)       # → 11.8\n",
        "print(torchvision.__version__)  # → 0.18.0+cu118 (hoặc gần đó)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0P_KxzFM2nw",
        "outputId": "4adba42b-a420-4b29-ec1a-faebd3954aa6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "12.4\n",
            "0.21.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "\n",
        "# Load CodeBERT\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "\n",
        "# Tokenize\n",
        "inputs = tokenizer(contract_code, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "\n",
        "# Get hidden states\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Use [CLS] token embedding as sentence representation\n",
        "codebert_vec = outputs.last_hidden_state[:, 0, :]  # shape: [1, 768]. Now embedding is a 768-dimensional vector that represents your entire contract.\n"
      ],
      "metadata": {
        "id": "AR4zuzTiM5Tt"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(codebert_vec.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnoPXAmgNyf3",
        "outputId": "4fdf8d08-8e22-438a-9557-4c7b78bc95ec"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functional sematics"
      ],
      "metadata": {
        "id": "y4T8h0HTM_KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
        "client = OpenAI()\n",
        "\n",
        "def analyze_funtional_sematics_with_gpt(code):\n",
        "    \"\"\"Gửi nội dung file Solidity đến OpenAI GPT-3.5 để phân tích\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "        What is the purpose of the above code snippet? Please\n",
        "        summarize the answer in one sentence with the following format:\n",
        "        “Abstract purpose:”.\n",
        "\n",
        "        Please summarize the functions of the above code snippet in the list\n",
        "        format without any other explanation: “Detail Behaviors: 1. 2. 3...”\n",
        "\n",
        "        Here is the file content:\n",
        "        {code}\n",
        "                \"\"\"\n",
        "\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"developer\", \"content\": \"You are a specialist in Smart Contract analysing, talk like an expert in Smart Contract\"},\n",
        "                {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt,\n",
        "\n",
        "                },\n",
        "            ],\n",
        "        )\n",
        "        functional_sematic_of_code = completion.choices[0].message.content\n",
        "\n",
        "        print(\"functional sematics of the detected code: \", functional_sematic_of_code)\n",
        "        return functional_sematic_of_code\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Lỗi khi gọi OpenAI API: {e}\")\n",
        "        return None  # ✅ safely return None in case of error\n",
        "\n"
      ],
      "metadata": {
        "id": "2pJYjYPmNApc"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Nhận input từ user\n",
        "user_query = contract_code\n",
        "# 2. Tìm Purpose gần nhất với input bằng analyze funtional sematics\n",
        "functional_sematic_of_code = analyze_funtional_sematics_with_gpt(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSzabVZ2NFoL",
        "outputId": "42eae739-9c9b-4921-eb77-da8afa12bbe9"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "functional sematics of the detected code:  Abstract purpose: Demonstrating vulnerability to integer overflow and underflow in smart contracts.\n",
            "\n",
            "Detail Behaviors: \n",
            "1. Initialize the balance to maximum uint8 value (255).\n",
            "2. increment(uint8 value) function adds the given value to the balance, vulnerable to overflow.\n",
            "3. decrement(uint8 value) function subtracts the given value from the balance, vulnerable to underflow.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "# Khởi tạo embeddings từ HuggingFace\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "VzhMihtLNGeF"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minilm_vec = embeddings.embed_query(functional_sematic_of_code)"
      ],
      "metadata": {
        "id": "AEii4Mj4NIEi"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minilm_vec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFDo-teOQBPD",
        "outputId": "86e48627-3cb5-4fbc-f2ef-3f360253f518"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.09040491282939911,\n",
              " 0.11969856172800064,\n",
              " -0.013197259046137333,\n",
              " -0.06696122139692307,\n",
              " -0.04392675682902336,\n",
              " -0.023971274495124817,\n",
              " -0.023390578106045723,\n",
              " 0.13786694407463074,\n",
              " -0.025966383516788483,\n",
              " 0.03325320780277252,\n",
              " -0.03791738674044609,\n",
              " -0.03299829736351967,\n",
              " 0.051450882107019424,\n",
              " -0.0670013502240181,\n",
              " -0.020558364689350128,\n",
              " 0.009238573722541332,\n",
              " -0.011442509479820728,\n",
              " 0.08554257452487946,\n",
              " -0.09227226674556732,\n",
              " -0.014043035916984081,\n",
              " 0.08120373636484146,\n",
              " 0.04038601741194725,\n",
              " -0.09254154562950134,\n",
              " 0.04287955164909363,\n",
              " -0.06114311143755913,\n",
              " -0.029519155621528625,\n",
              " -0.053836602717638016,\n",
              " -0.021838918328285217,\n",
              " 0.05951584875583649,\n",
              " -0.07238473743200302,\n",
              " 0.03312932699918747,\n",
              " 0.1157490611076355,\n",
              " 0.04916222766041756,\n",
              " 0.021047895774245262,\n",
              " -0.07237692922353745,\n",
              " 0.014219474978744984,\n",
              " 0.012038336135447025,\n",
              " -0.025772906839847565,\n",
              " 0.03302706032991409,\n",
              " 0.05074562132358551,\n",
              " -0.04352254420518875,\n",
              " -0.02142510563135147,\n",
              " -0.006665055174380541,\n",
              " 0.03439128026366234,\n",
              " -0.020842231810092926,\n",
              " -0.04700889438390732,\n",
              " -0.04402676969766617,\n",
              " -0.01657930761575699,\n",
              " -0.05296020209789276,\n",
              " 0.017208926379680634,\n",
              " 0.049052800983190536,\n",
              " 0.10324335843324661,\n",
              " -0.006194018293172121,\n",
              " 0.11759848892688751,\n",
              " -0.07756606489419937,\n",
              " -0.11029653251171112,\n",
              " -0.030186261981725693,\n",
              " -0.09138844162225723,\n",
              " 0.002370679285377264,\n",
              " 0.039607591927051544,\n",
              " 0.030888443812727928,\n",
              " 0.02421163208782673,\n",
              " 0.05941382795572281,\n",
              " 0.015789197757840157,\n",
              " 0.008723140694200993,\n",
              " -0.0613219253718853,\n",
              " 0.05797188729047775,\n",
              " -0.01192446332424879,\n",
              " -0.06242535635828972,\n",
              " 0.08546945452690125,\n",
              " 0.052026718854904175,\n",
              " -0.023006178438663483,\n",
              " -0.06507445871829987,\n",
              " -0.008349188603460789,\n",
              " 0.06780789792537689,\n",
              " -0.011978096328675747,\n",
              " -0.05131830275058746,\n",
              " -0.01502997800707817,\n",
              " -0.02373497746884823,\n",
              " -0.057673364877700806,\n",
              " 0.02770083397626877,\n",
              " 0.003446665359660983,\n",
              " 0.008954724296927452,\n",
              " -0.03513626009225845,\n",
              " 0.07399465888738632,\n",
              " -0.04024993255734444,\n",
              " 0.0025872604455798864,\n",
              " 0.03000076301395893,\n",
              " 0.16042570769786835,\n",
              " 0.033554691821336746,\n",
              " -0.0056110224686563015,\n",
              " 0.07072553783655167,\n",
              " 0.05235061049461365,\n",
              " 0.03031754679977894,\n",
              " 0.05658368766307831,\n",
              " 0.015510721132159233,\n",
              " -0.0064475624822080135,\n",
              " -0.06483530253171921,\n",
              " -0.04224744811654091,\n",
              " 0.028026945888996124,\n",
              " -0.056268393993377686,\n",
              " 0.08388091623783112,\n",
              " -0.054869405925273895,\n",
              " 0.0374034121632576,\n",
              " 0.02783917635679245,\n",
              " -0.04224734380841255,\n",
              " 0.07766899466514587,\n",
              " -0.06978940218687057,\n",
              " -0.0032371024135500193,\n",
              " -0.052642498165369034,\n",
              " 0.054896239191293716,\n",
              " 0.004627575632184744,\n",
              " 0.08159948140382767,\n",
              " -0.05775410309433937,\n",
              " 0.024572080001235008,\n",
              " -0.0011884283740073442,\n",
              " -0.03948657959699631,\n",
              " 0.041940025985240936,\n",
              " -0.052060484886169434,\n",
              " -0.010868477635085583,\n",
              " 0.058870382606983185,\n",
              " 0.07315068691968918,\n",
              " -0.12408004701137543,\n",
              " 0.057093773037195206,\n",
              " -0.0773455873131752,\n",
              " 0.07415183633565903,\n",
              " -0.004632232710719109,\n",
              " 3.7837197873351654e-33,\n",
              " -0.04000554606318474,\n",
              " -0.060010045766830444,\n",
              " -0.003623273456469178,\n",
              " 0.037332553416490555,\n",
              " 0.04039544239640236,\n",
              " -0.02470003254711628,\n",
              " -0.030976468697190285,\n",
              " -0.022396810352802277,\n",
              " -0.07130657881498337,\n",
              " 0.06377943605184555,\n",
              " 0.06391244381666183,\n",
              " 0.03395072743296623,\n",
              " 0.015773165971040726,\n",
              " 0.013618160039186478,\n",
              " -0.019329814240336418,\n",
              " -0.10166268795728683,\n",
              " -0.004166106227785349,\n",
              " 0.02568136528134346,\n",
              " 0.12483888864517212,\n",
              " -0.023439466953277588,\n",
              " 0.02074364945292473,\n",
              " -0.14336606860160828,\n",
              " -0.039462413638830185,\n",
              " -0.0481066070497036,\n",
              " 0.08581860363483429,\n",
              " 0.0671548992395401,\n",
              " -0.014125595800578594,\n",
              " -0.012855052947998047,\n",
              " 0.03380858525633812,\n",
              " -0.001512888353317976,\n",
              " -0.014719492755830288,\n",
              " -0.025425849482417107,\n",
              " -0.04467746987938881,\n",
              " 0.007389577571302652,\n",
              " -0.011547704227268696,\n",
              " -0.03729557618498802,\n",
              " -0.017029542475938797,\n",
              " 0.03462876006960869,\n",
              " -0.0004062819934915751,\n",
              " 0.040477458387613297,\n",
              " -0.09219522774219513,\n",
              " -0.004473460838198662,\n",
              " -0.05361266806721687,\n",
              " 0.019555410370230675,\n",
              " 0.05206744372844696,\n",
              " 0.0008714590803720057,\n",
              " 0.036139652132987976,\n",
              " 0.04372221976518631,\n",
              " 0.02039923146367073,\n",
              " 0.011690083891153336,\n",
              " -0.07480017095804214,\n",
              " 0.04096611216664314,\n",
              " -0.07636825740337372,\n",
              " -0.011411677114665508,\n",
              " -0.05162735655903816,\n",
              " -0.05133624002337456,\n",
              " 0.03304780274629593,\n",
              " -0.03392722085118294,\n",
              " -0.07225515693426132,\n",
              " 0.08558845520019531,\n",
              " -0.005402390379458666,\n",
              " 0.020921340212225914,\n",
              " -0.038024816662073135,\n",
              " -0.057903509587049484,\n",
              " -0.07499070465564728,\n",
              " 0.006795444991439581,\n",
              " -0.06410481035709381,\n",
              " -0.03088129684329033,\n",
              " 0.04420734569430351,\n",
              " 0.057172615081071854,\n",
              " -0.11576543748378754,\n",
              " 0.007118501700460911,\n",
              " -0.06709615886211395,\n",
              " 0.10701622813940048,\n",
              " -0.07592029869556427,\n",
              " -0.010670671239495277,\n",
              " -0.0009011242655105889,\n",
              " 0.028110506013035774,\n",
              " 0.03724920004606247,\n",
              " -0.06645992398262024,\n",
              " -0.050706908106803894,\n",
              " 0.023753972724080086,\n",
              " 0.10558512061834335,\n",
              " 0.06504957377910614,\n",
              " 0.03707658499479294,\n",
              " -0.047797489911317825,\n",
              " -0.05851505324244499,\n",
              " -0.02897012233734131,\n",
              " -0.07323191314935684,\n",
              " -0.019933151081204414,\n",
              " 0.006912666838616133,\n",
              " -0.08160265535116196,\n",
              " 0.12169951945543289,\n",
              " 0.0031566631514579058,\n",
              " 0.047408562153577805,\n",
              " -5.1583498606844564e-33,\n",
              " -0.1647011637687683,\n",
              " 0.04920767620205879,\n",
              " -0.09198038280010223,\n",
              " 0.0854860320687294,\n",
              " 0.002824400784447789,\n",
              " -0.039561688899993896,\n",
              " 0.01371832750737667,\n",
              " 0.04060071334242821,\n",
              " 0.003328980877995491,\n",
              " -0.028826620429754257,\n",
              " -0.03103433921933174,\n",
              " 0.059171248227357864,\n",
              " -0.034668244421482086,\n",
              " -0.010208489373326302,\n",
              " 0.072125144302845,\n",
              " -0.08363255858421326,\n",
              " -0.07784706354141235,\n",
              " 0.03359870985150337,\n",
              " 0.014355339109897614,\n",
              " -0.02028016746044159,\n",
              " 0.03374073654413223,\n",
              " 0.025521311908960342,\n",
              " -0.021595433354377747,\n",
              " 0.015097545459866524,\n",
              " 0.00142921251244843,\n",
              " 0.06375215947628021,\n",
              " -0.010594061575829983,\n",
              " -0.02816743776202202,\n",
              " 0.06397882103919983,\n",
              " 0.0220523402094841,\n",
              " 0.003630236489698291,\n",
              " 0.0013528581475839019,\n",
              " -0.018770286813378334,\n",
              " 0.018769176676869392,\n",
              " 0.00026827017427422106,\n",
              " -0.08139060437679291,\n",
              " 0.04593838006258011,\n",
              " -0.02369428612291813,\n",
              " -0.018217401579022408,\n",
              " -0.0007794277626089752,\n",
              " 0.06607955694198608,\n",
              " -0.036757197231054306,\n",
              " 0.0125293442979455,\n",
              " 0.049706242978572845,\n",
              " -0.013622472994029522,\n",
              " 0.020484503358602524,\n",
              " 0.02768140845000744,\n",
              " 0.014501525089144707,\n",
              " 0.05608177185058594,\n",
              " -0.07056690752506256,\n",
              " 0.030265137553215027,\n",
              " -0.012350701726973057,\n",
              " 0.005833103321492672,\n",
              " 0.08140134811401367,\n",
              " -0.0011775919701904058,\n",
              " 0.05990572273731232,\n",
              " 0.07329561561346054,\n",
              " 0.013805495575070381,\n",
              " 0.09308608621358871,\n",
              " 0.03326753154397011,\n",
              " 0.004548393189907074,\n",
              " 0.1086825430393219,\n",
              " 0.05490654706954956,\n",
              " -0.028955204412341118,\n",
              " -0.05015922337770462,\n",
              " 0.0005258213495835662,\n",
              " -0.06277642399072647,\n",
              " -0.0030990783125162125,\n",
              " -0.029317175969481468,\n",
              " 0.027213796973228455,\n",
              " 0.1076500192284584,\n",
              " -0.0007176999934017658,\n",
              " 0.016088183969259262,\n",
              " -0.03448917344212532,\n",
              " 0.05668294429779053,\n",
              " -0.05755775421857834,\n",
              " -0.01840248890221119,\n",
              " -0.003285502316430211,\n",
              " 0.029215123504400253,\n",
              " 0.02516190893948078,\n",
              " -0.02869603782892227,\n",
              " 0.057524118572473526,\n",
              " 0.003051778534427285,\n",
              " 0.010953923687338829,\n",
              " -0.07098399847745895,\n",
              " -0.005084786098450422,\n",
              " 0.05840048938989639,\n",
              " 0.0008496458176523447,\n",
              " -0.026651132851839066,\n",
              " 0.04253312200307846,\n",
              " -0.06381110846996307,\n",
              " 0.050872981548309326,\n",
              " -0.10702820122241974,\n",
              " 0.00943512748926878,\n",
              " -0.045113299041986465,\n",
              " -4.201115544333334e-08,\n",
              " -0.013581045903265476,\n",
              " -0.07227432727813721,\n",
              " -0.02763242833316326,\n",
              " -0.08405156433582306,\n",
              " 0.07555477321147919,\n",
              " 0.014876213856041431,\n",
              " 0.02373732253909111,\n",
              " -0.043949637562036514,\n",
              " 0.009373069740831852,\n",
              " -0.008166746236383915,\n",
              " 0.01866193860769272,\n",
              " 0.01646687462925911,\n",
              " 0.04138115048408508,\n",
              " 0.011399884708225727,\n",
              " 0.005157340317964554,\n",
              " -0.01590535044670105,\n",
              " -0.004644846078008413,\n",
              " -0.0018314571352675557,\n",
              " -0.06474878638982773,\n",
              " -0.0011604895116761327,\n",
              " -0.046737976372241974,\n",
              " 0.03783257678151131,\n",
              " -0.0037131458520889282,\n",
              " -0.0657879039645195,\n",
              " 0.02345307730138302,\n",
              " -0.04575251415371895,\n",
              " -0.026040254160761833,\n",
              " 0.09862591326236725,\n",
              " 0.060353051871061325,\n",
              " -0.023844625800848007,\n",
              " 0.0530821792781353,\n",
              " 0.07088039815425873,\n",
              " 0.022393574938178062,\n",
              " 0.03637148439884186,\n",
              " 0.018150558695197105,\n",
              " 0.05867428705096245,\n",
              " -0.01353277638554573,\n",
              " 0.01323259249329567,\n",
              " 0.025973469018936157,\n",
              " -0.01740192249417305,\n",
              " -0.10311532020568848,\n",
              " -0.044642314314842224,\n",
              " -0.018759913742542267,\n",
              " -0.025655660778284073,\n",
              " 0.03055817447602749,\n",
              " -0.0335744209587574,\n",
              " -0.019997496157884598,\n",
              " -0.006789001170545816,\n",
              " -0.021389685571193695,\n",
              " -0.004502320662140846,\n",
              " -0.04263049736618996,\n",
              " 0.009537938982248306,\n",
              " 0.056188710033893585,\n",
              " 0.055805180221796036,\n",
              " 0.0298443716019392,\n",
              " -0.02437683194875717,\n",
              " -0.09119284152984619,\n",
              " -0.030292388051748276,\n",
              " -0.041377920657396317,\n",
              " 0.03947792947292328,\n",
              " -0.007793084252625704,\n",
              " -0.06496714055538177,\n",
              " 0.0034678971860557795,\n",
              " -0.007230089511722326]"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## concat"
      ],
      "metadata": {
        "id": "fGgD3_qrNKSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "codebert_vec = codebert_vec.squeeze(0).detach().numpy()\n",
        "cfg_vec = cfg_vec.mean(dim=0).detach().numpy()\n",
        "minilm_vec = np.array(minilm_vec, dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "V7ZzuiEMNK95"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_embedding = np.concatenate([codebert_vec, minilm_vec, cfg_vec])\n"
      ],
      "metadata": {
        "id": "Lmv3i4fBQvMu"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkXVBI92Qw0Y",
        "outputId": "4b8ace63-ee14-4441-8e85-2bb4f0b79d10"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1216,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train MLP"
      ],
      "metadata": {
        "id": "eYda4HgZWc0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load file Excel ===\n",
        "df = pd.read_excel(\"embedding for MLP.xlsx\")\n",
        "df = df.dropna(subset=[\"codebert_embedding\", \"minilm_embedding\", \"cfg_embedding\"]).reset_index(drop=True)\n",
        "\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "I2_BdGJOWbqt"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# === Load file Excel ===\n",
        "# df = pd.read_excel(\"embedding for MLP.xlsx\")\n",
        "# df = df.dropna(subset=[\"codebert_embedding\", \"minilm_embedding\", \"cfg_embedding\"]).reset_index(drop=True)\n",
        "\n",
        "# === Chuyển từ chuỗi → mảng float ===\n",
        "def parse_embedding(x):\n",
        "    return np.array(ast.literal_eval(x), dtype=np.float32)\n",
        "\n",
        "df[\"codebert_embedding\"] = df[\"codebert_embedding\"].apply(parse_embedding)\n",
        "df[\"minilm_embedding\"] = df[\"minilm_embedding\"].apply(parse_embedding)\n",
        "df[\"cfg_embedding\"] = df[\"cfg_embedding\"].apply(parse_embedding)\n",
        "\n",
        "# === Nối tất cả embedding lại thành 1 vector duy nhất ===\n",
        "df[\"combined\"] = df.apply(lambda row: np.concatenate([\n",
        "    row[\"codebert_embedding\"],\n",
        "    row[\"minilm_embedding\"],\n",
        "    row[\"cfg_embedding\"]\n",
        "]), axis=1)\n",
        "\n",
        "X = np.stack(df[\"combined\"].values)  # Input features\n",
        "\n",
        "# === Chuẩn hóa label thành số\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df[\"label\"])  # Ground truth labels (0→n)\n",
        "\n",
        "# === Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# === Chuyển sang Tensor\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# === Định nghĩa mô hình MLP\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(MLP, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "model = MLP(input_size=X.shape[1], num_classes=len(label_encoder.classes_))\n",
        "\n",
        "# === Loss + Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# === Train\n",
        "print(\"🔁 Training started...\")\n",
        "for epoch in range(120):  # Bạn có thể thay đổi số epoch tùy dataset\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"📆 Epoch {epoch+1} - Loss: {running_loss:.4f}\")\n",
        "\n",
        "# === Evaluate\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(X_test_tensor)\n",
        "    predictions = torch.argmax(outputs, dim=1)\n",
        "    acc = (predictions == y_test_tensor).sum().item() / len(y_test_tensor)\n",
        "    print(f\"\\n✅ Accuracy on test set: {acc * 100:.2f}%\")\n",
        "\n",
        "# === Optional: In ra các label\n",
        "print(\"\\n📌 Label Mapping:\")\n",
        "for i, label in enumerate(label_encoder.classes_):\n",
        "    print(f\"{i} → {label}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOR9pizfXVac",
        "outputId": "cd481304-efe8-4e46-a63a-a6eda3802e3f"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔁 Training started...\n",
            "📆 Epoch 1 - Loss: 15.0204\n",
            "📆 Epoch 2 - Loss: 13.6760\n",
            "📆 Epoch 3 - Loss: 13.2979\n",
            "📆 Epoch 4 - Loss: 13.1330\n",
            "📆 Epoch 5 - Loss: 12.8675\n",
            "📆 Epoch 6 - Loss: 12.4432\n",
            "📆 Epoch 7 - Loss: 12.6128\n",
            "📆 Epoch 8 - Loss: 12.0403\n",
            "📆 Epoch 9 - Loss: 11.5792\n",
            "📆 Epoch 10 - Loss: 11.5377\n",
            "📆 Epoch 11 - Loss: 10.7948\n",
            "📆 Epoch 12 - Loss: 11.1081\n",
            "📆 Epoch 13 - Loss: 9.9582\n",
            "📆 Epoch 14 - Loss: 9.3884\n",
            "📆 Epoch 15 - Loss: 9.4702\n",
            "📆 Epoch 16 - Loss: 8.3568\n",
            "📆 Epoch 17 - Loss: 7.9872\n",
            "📆 Epoch 18 - Loss: 7.3274\n",
            "📆 Epoch 19 - Loss: 6.5861\n",
            "📆 Epoch 20 - Loss: 6.0958\n",
            "📆 Epoch 21 - Loss: 5.6287\n",
            "📆 Epoch 22 - Loss: 4.7420\n",
            "📆 Epoch 23 - Loss: 5.3015\n",
            "📆 Epoch 24 - Loss: 5.1419\n",
            "📆 Epoch 25 - Loss: 4.5555\n",
            "📆 Epoch 26 - Loss: 4.2762\n",
            "📆 Epoch 27 - Loss: 3.5138\n",
            "📆 Epoch 28 - Loss: 3.6068\n",
            "📆 Epoch 29 - Loss: 3.2171\n",
            "📆 Epoch 30 - Loss: 3.0077\n",
            "📆 Epoch 31 - Loss: 2.8049\n",
            "📆 Epoch 32 - Loss: 2.7187\n",
            "📆 Epoch 33 - Loss: 2.4794\n",
            "📆 Epoch 34 - Loss: 2.7751\n",
            "📆 Epoch 35 - Loss: 2.0601\n",
            "📆 Epoch 36 - Loss: 2.2920\n",
            "📆 Epoch 37 - Loss: 2.0858\n",
            "📆 Epoch 38 - Loss: 2.1493\n",
            "📆 Epoch 39 - Loss: 1.6728\n",
            "📆 Epoch 40 - Loss: 1.5018\n",
            "📆 Epoch 41 - Loss: 1.6445\n",
            "📆 Epoch 42 - Loss: 1.3267\n",
            "📆 Epoch 43 - Loss: 1.4498\n",
            "📆 Epoch 44 - Loss: 1.1842\n",
            "📆 Epoch 45 - Loss: 1.1123\n",
            "📆 Epoch 46 - Loss: 0.8612\n",
            "📆 Epoch 47 - Loss: 0.9193\n",
            "📆 Epoch 48 - Loss: 0.7304\n",
            "📆 Epoch 49 - Loss: 0.6469\n",
            "📆 Epoch 50 - Loss: 0.7102\n",
            "📆 Epoch 51 - Loss: 0.9357\n",
            "📆 Epoch 52 - Loss: 0.8703\n",
            "📆 Epoch 53 - Loss: 0.7226\n",
            "📆 Epoch 54 - Loss: 0.5909\n",
            "📆 Epoch 55 - Loss: 0.5786\n",
            "📆 Epoch 56 - Loss: 0.6611\n",
            "📆 Epoch 57 - Loss: 0.6143\n",
            "📆 Epoch 58 - Loss: 0.6143\n",
            "📆 Epoch 59 - Loss: 0.5764\n",
            "📆 Epoch 60 - Loss: 0.3296\n",
            "📆 Epoch 61 - Loss: 0.3407\n",
            "📆 Epoch 62 - Loss: 0.3954\n",
            "📆 Epoch 63 - Loss: 0.2866\n",
            "📆 Epoch 64 - Loss: 0.2937\n",
            "📆 Epoch 65 - Loss: 0.2308\n",
            "📆 Epoch 66 - Loss: 0.2779\n",
            "📆 Epoch 67 - Loss: 0.2728\n",
            "📆 Epoch 68 - Loss: 0.3485\n",
            "📆 Epoch 69 - Loss: 0.3215\n",
            "📆 Epoch 70 - Loss: 0.3022\n",
            "📆 Epoch 71 - Loss: 0.2659\n",
            "📆 Epoch 72 - Loss: 0.2595\n",
            "📆 Epoch 73 - Loss: 0.2059\n",
            "📆 Epoch 74 - Loss: 0.1288\n",
            "📆 Epoch 75 - Loss: 0.1954\n",
            "📆 Epoch 76 - Loss: 0.1827\n",
            "📆 Epoch 77 - Loss: 0.2185\n",
            "📆 Epoch 78 - Loss: 0.1610\n",
            "📆 Epoch 79 - Loss: 0.1287\n",
            "📆 Epoch 80 - Loss: 0.1850\n",
            "📆 Epoch 81 - Loss: 0.2030\n",
            "📆 Epoch 82 - Loss: 0.1829\n",
            "📆 Epoch 83 - Loss: 0.1047\n",
            "📆 Epoch 84 - Loss: 0.2124\n",
            "📆 Epoch 85 - Loss: 0.1841\n",
            "📆 Epoch 86 - Loss: 0.1537\n",
            "📆 Epoch 87 - Loss: 0.0749\n",
            "📆 Epoch 88 - Loss: 0.1290\n",
            "📆 Epoch 89 - Loss: 0.1942\n",
            "📆 Epoch 90 - Loss: 0.1232\n",
            "📆 Epoch 91 - Loss: 0.1510\n",
            "📆 Epoch 92 - Loss: 0.1602\n",
            "📆 Epoch 93 - Loss: 0.0652\n",
            "📆 Epoch 94 - Loss: 0.0662\n",
            "📆 Epoch 95 - Loss: 0.0652\n",
            "📆 Epoch 96 - Loss: 0.0793\n",
            "📆 Epoch 97 - Loss: 0.0562\n",
            "📆 Epoch 98 - Loss: 0.0565\n",
            "📆 Epoch 99 - Loss: 0.1512\n",
            "📆 Epoch 100 - Loss: 0.1355\n",
            "📆 Epoch 101 - Loss: 0.1002\n",
            "📆 Epoch 102 - Loss: 0.0987\n",
            "📆 Epoch 103 - Loss: 0.0749\n",
            "📆 Epoch 104 - Loss: 0.0525\n",
            "📆 Epoch 105 - Loss: 0.0548\n",
            "📆 Epoch 106 - Loss: 0.1026\n",
            "📆 Epoch 107 - Loss: 0.0641\n",
            "📆 Epoch 108 - Loss: 0.0668\n",
            "📆 Epoch 109 - Loss: 0.0826\n",
            "📆 Epoch 110 - Loss: 0.0941\n",
            "📆 Epoch 111 - Loss: 0.0574\n",
            "📆 Epoch 112 - Loss: 0.0270\n",
            "📆 Epoch 113 - Loss: 0.0235\n",
            "📆 Epoch 114 - Loss: 0.0467\n",
            "📆 Epoch 115 - Loss: 0.0330\n",
            "📆 Epoch 116 - Loss: 0.0778\n",
            "📆 Epoch 117 - Loss: 0.0402\n",
            "📆 Epoch 118 - Loss: 0.0431\n",
            "📆 Epoch 119 - Loss: 0.0410\n",
            "📆 Epoch 120 - Loss: 0.0392\n",
            "\n",
            "✅ Accuracy on test set: 50.00%\n",
            "\n",
            "📌 Label Mapping:\n",
            "0 → access_control\n",
            "1 → arithmetic\n",
            "2 → bad_randomness\n",
            "3 → denial_of_service\n",
            "4 → front_running\n",
            "5 → other\n",
            "6 → reentrancy\n",
            "7 → short_addresses\n",
            "8 → time_manipulation\n",
            "9 → unchecked_low_level_calls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# === Confusion Matrix + Classification Report ===\n",
        "print(\"\\n📊 Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_test_tensor.numpy(), predictions.numpy())\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n📈 Classification Report:\")\n",
        "report = classification_report(\n",
        "    y_test_tensor.numpy(),\n",
        "    predictions.numpy(),\n",
        "    target_names=label_encoder.classes_,\n",
        "    digits=3\n",
        ")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "ch8V9WATU3rX",
        "outputId": "df62c1e4-9234-4d82-c165-59ef2fdd2863"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Confusion Matrix:\n",
            "[[0 1 0 0 0 0 0 0 0]\n",
            " [0 2 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 4 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 1 1 0 0 0 0 0 0]\n",
            " [3 0 0 0 0 1 0 0 7]]\n",
            "\n",
            "📈 Classification Report:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Number of classes, 9, does not match size of target_names, 10. Try specifying the labels parameter",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-169-2675681142.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n📈 Classification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m report = classification_report(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_test_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2691\u001b[0m             )\n\u001b[1;32m   2692\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2694\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Number of classes, 9, does not match size of target_names, 10. Try specifying the labels parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# giả sử bạn đã có 3 embedding:\n",
        "# - codebert_vec: shape (768,)\n",
        "# - minilm_vec: shape (384,)\n",
        "# - cfg_vec: shape (64,)\n",
        "\n",
        "final_embedding = np.concatenate([codebert_vec, minilm_vec, cfg_vec])\n",
        "input_tensor = torch.tensor([final_embedding], dtype=torch.float32)\n",
        "\n",
        "# Dự đoán\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    pred_label_id = torch.argmax(output, dim=1).item()\n",
        "    label_name = label_encoder.classes_[pred_label_id]\n",
        "    print(\" Predicted label:\", label_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVkdjTGpNQop",
        "outputId": "e77edaee-47ad-4d57-c966-c302f66f50ae"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Predicted label: arithmetic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lAf01NN2RDH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
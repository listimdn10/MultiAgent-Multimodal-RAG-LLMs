# consensus_agent.py (Phi√™n b·∫£n ƒë√£ s·ª≠a)
import json
import os
import re
from typing import Type
from pydantic import BaseModel, Field
from crewai import Agent, Task, Crew, Process, LLM
from crewai.tools import BaseTool

# --- Import c√°c th∆∞ vi·ªán RAG ---
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings


# ===========================
# --- KHU V·ª∞C LO·∫†I B·ªé LOGIC TR√çCH XU·∫§T MD ---
# ===========================
# ‚úÖ X√≥a to√†n b·ªô logic tr√≠ch xu·∫•t t·ª´ 'multimodal-Audit.md' th√†nh 'multi_modal.md'
#    v√¨ ch√∫ng ta s·∫Ω ƒë·ªçc tr·ª±c ti·∫øp 'explainer_output.json'


# ===========================
# --- CONFIG GLOBAL PATH (ƒê√É C·∫¨P NH·∫¨T) ---
# ===========================

SOURCE_PATH = "contracts/sample.sol"
RAG_PATH = "rag_output.json"
EXPLAINER_PATH = "explainer_output.json" # <--- ƒê√É S·ª¨A: ƒê·ªçc file JSON tr·ª±c ti·∫øp

def safe_read_text(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        print(f"‚ö†Ô∏è Could not read text file {path}: {e}")
        return ""

def safe_read_json(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"‚ö†Ô∏è Could not read JSON file {path}: {e}")
        return {}

# --- Read content once globally
SOURCE_CONTENT = safe_read_text(SOURCE_PATH)
RAG_CONTENT = safe_read_json(RAG_PATH)
# ‚úÖ ƒê·ªåC EXPLAINER CONTENT D∆Ø·ªöI D·∫†NG JSON
EXPLAINER_CONTENT = safe_read_json(EXPLAINER_PATH)


# ===========================
# --- Local LLM (Ollama)
# ===========================
llm_local = LLM(
    model="ollama/llama3:8b-instruct-q8_0",
    base_url="http://localhost:11434"
)

# ===========================
# --- THI·∫æT L·∫¨P VECTORSTORE
# ===========================
print("ƒêang t·∫£i m√¥ h√¨nh embeddings (local)...")
embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")

print("ƒêang t·∫£i ChromaDB t·ª´ disk...")
vector_store = Chroma(
    persist_directory="knowledge_base/chroma_db", 
    embedding_function=embeddings
)
# T·∫°o retriever, k=2 nghƒ©a l√† l·∫•y 2 k·∫øt qu·∫£ li√™n quan nh·∫•t
retriever = vector_store.as_retriever(search_kwargs={"k": 1})
print("‚úÖ Vectorstore ƒë√£ s·∫µn s√†ng.")


# ===========================
# --- Input Schema (Gi·ªØ nguy√™n)
# ===========================
class ConsensusInput(BaseModel):
    source_path: str = Field(SOURCE_PATH, description="Path to the source Solidity file")
    rag_path: str = Field(RAG_PATH, description="Path to the RAG agent output JSON")
    explainer_path: str = Field(EXPLAINER_PATH, description="Path to the Explainer agent output JSON")


# ===========================
# --- Consensus Tool Definition
# ===========================
class ConsensusTool(BaseTool):
    name: str = "ConsensusTool"
    description: str = (
        "Compare two audit outputs (RAG and Explainer) plus the source code, "
        "then decide which audit is more accurate or merge their results."
    )
    args_schema: Type[BaseModel] = ConsensusInput

    def __init__(self, llm=None, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._llm = llm

    # ... (H√†m _call_llm gi·ªØ nguy√™n) ...
    def _call_llm(self, prompt: str):
        if self._llm is None:
            raise RuntimeError("‚ùå No LLM provided to ConsensusTool.")
        errors = []
        for method in ["invoke", "generate", "call"]:
            try:
                fn = getattr(self._llm, method, None)
                if callable(fn):
                    resp = fn(prompt)
                    if isinstance(resp, str):
                        return resp
                    if hasattr(resp, "content"):
                        return resp.content
                    if hasattr(resp, "text"):
                        return resp.text
                    return str(resp)
            except Exception as e:
                errors.append(f"{method} failed: {e}")
        raise RuntimeError("All LLM invocation attempts failed: " + " | ".join(errors))

    # ---------- Main Run (ƒê√É C·∫¨P NH·∫¨T LOGIC) ----------
    def _run(self, source_path: str, rag_path: str, explainer_path: str) -> dict:
        # 1. L·∫•y n·ªôi dung global
        source_code = SOURCE_CONTENT
        rag_json = RAG_CONTENT
        explainer_json = EXPLAINER_CONTENT # ‚úÖ Gi·ªù l√† JSON

        # 2. (C·∫¨P NH·∫¨T) Tr√≠ch xu·∫•t Vuln Types
        rag_vuln_type = rag_json.get("Predict", "") or rag_json.get("vuln_type", "")
        
        # ‚úÖ L·∫•y tr·ª±c ti·∫øp t·ª´ key 'vuln_type' trong JSON c·ªßa Explainer
        explainer_vuln_type = explainer_json.get("vuln_type", "") 
        



        print(f"üîç ƒê√£ x√°c ƒë·ªãnh Vuln Types: RAG='{rag_vuln_type}', Explainer='{explainer_vuln_type}'")

        # 4. (Gi·ªØ nguy√™n) Truy v·∫•n Vectorstore T√ÅCH BI·ªÜT
        
        # H√†m helper ƒë·ªÉ truy v·∫•n v√† g·ªôp context
        def get_knowledge_context(query: str) -> str:
            if not query:
                return "No vulnerability type provided."
            try:
                print(f"üìö Truy v·∫•n KB cho: '{query}'")
                docs = retriever.invoke(query) # retriever ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü global (k=1)
                # G·ªôp n·ªôi dung c·ªßa c√°c t√†i li·ªáu t√¨m ƒë∆∞·ª£c
                return "\n\n---\n\n".join([doc.page_content for doc in docs])
            except Exception as e:
                print(f"‚ö†Ô∏è L·ªói truy v·∫•n vectorstore: {e}")
                return f"Error retrieving knowledge: {e}"

        # L·∫•y context ri√™ng cho RAG
        rag_knowledge_context = get_knowledge_context(rag_vuln_type)
        
        # L·∫•y context ri√™ng cho Explainer
        explainer_knowledge_context = get_knowledge_context(explainer_vuln_type)

        print(f"üìö ƒê√£ truy xu·∫•t {len(rag_knowledge_context)} chars cho RAG.")
        print(f"üìö ƒê√£ truy xu·∫•t {len(explainer_knowledge_context)} chars cho Explainer.")

        # 5. Build prompt v·ªõi ki·∫øn th·ª©c T√ÅCH BI·ªÜT (ƒê√É C·∫¨P NH·∫¨T)
        prompt = f"""
        You are an expert smart contract auditor. You will compare two audit reports 
        and the original source code, using the specific knowledge context provided for each report.

        --- SOURCE CODE ---
        {source_code}
        --- END SOURCE CODE ---


        --- RAG AGENT OUTPUT ---
        {json.dumps(rag_json, ensure_ascii=False, indent=2)}
        
        --- RAG KNOWLEDGE CONTEXT (Ki·∫øn th·ª©c cho RAG) ---
        {rag_knowledge_context}
        --- END RAG KNOWLEDGE ---


        --- EXPLAINER AGENT OUTPUT (N·ªôi dung file JSON ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh d·∫°ng) ---
        {json.dumps(explainer_json, ensure_ascii=False, indent=2)}

        --- EXPLAINER KNOWLEDGE CONTEXT (Ki·∫øn th·ª©c cho Explainer) ---
        {explainer_knowledge_context}
        --- END EXPLAINER KNOWLEDGE ---


        TASK:
        1) Evaluate the RAG AGENT OUTPUT. Is it accurate based on the SOURCE CODE and the RAG KNOWLEDGE CONTEXT?
        2) Evaluate the EXPLAINER AGENT OUTPUT. Is it accurate based on the SOURCE CODE and the EXPLAINER KNOWLEDGE CONTEXT?
        3) Decide which audit is MORE ACCURATE: "RAG", "Explainer", or "Merged" (if both have complementary, valid findings).
        4) Provide concise reasoning for your decision.
        5) Output ONLY valid JSON with this exact schema (no surrounding text):

        {{
            "decision": "RAG" | "Explainer" | "Merged",
            "reasoning": "concise reasons why you chose this decision, comparing both agents.",
            "final_vulnerability_summary": "one-sentence summary of the confirmed vulnerability",
            "confidence": float
        }}
        """

        # ... (Ph·∫ßn Call LLM v√† Parse JSON... gi·ªØ nguy√™n) ...
        # Call LLM
        try:
            llm_text = self._call_llm(prompt)
        except Exception as e:
            fallback = {
                "decision": "FAILED",
                "reasoning": f"LLM invocation failed: {e}",
                "final_vulnerability_summary": rag_json.get("vuln_type", "") or explainer_vuln_type,
                "confidence": 0.0
            }
            with open("consensus_output.json", "w", encoding="utf-8") as f:
                json.dump(fallback, f, ensure_ascii=False, indent=2)
            return fallback

        # Parse JSON output
        try:
            parsed = json.loads(llm_text)
        except Exception:
            m = re.search(r"\{.*\}", llm_text, re.DOTALL)
            parsed = json.loads(m.group(0)) if m else None

        if not parsed:
            result = {
                "decision": "Merged",
                "reasoning": llm_text.strip(),
                "final_vulnerability_summary": rag_json.get("Predict", "") or explainer_vuln_type,
                "confidence": 0.5
            }
        else:
            result = {
                "decision": parsed.get("decision", "Merged"),
                "reasoning": parsed.get("reasoning", ""),
                "final_vulnerability_summary": parsed.get("final_vulnerability_summary", ""),
                "confidence": float(parsed.get("confidence", 0.5))
            }

        with open("consensus_output.json", "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print("‚úÖ Saved consensus_output.json")
        return result


# ===========================
# --- Build Consensus Agent & Task (Gi·ªØ nguy√™n)
# ===========================
consensus_tool = ConsensusTool(llm=llm_local)

consensus_agent = Agent(
    role="Consensus Agent",
    goal="Compare RAG and Explainer audit outputs with source code to produce a unified, authoritative audit decision.",
    backstory="An expert smart contract auditor combining multiple model outputs to achieve the most reliable result.",
    tools=[consensus_tool],
    verbose=True,
    llm=llm_local,
)

consensus_task = Task(
    # M√¥ t·∫£ n√†y v·∫´n ch√≠nh x√°c, tool t·ª± x·ª≠ l√Ω vi·ªác l·∫•y data
    description="Use the ConsensusTool to analyze and merge the audit results. This tool already has all the necessary data.",
    expected_output="JSON containing decision, reasoning, final_vulnerability_summary, confidence.",
    agent=consensus_agent,
)


# ===========================
# --- Optional: run standalone (Gi·ªØ nguy√™n)
# ===========================
if __name__ == "__main__":
    crew = Crew(
        agents=[consensus_agent],
        tasks=[consensus_task],
        process=Process.sequential,
        verbose=True,
    )
    result = crew.kickoff()
    print("\n‚úÖ Final Consensus Result:")
    print(result)